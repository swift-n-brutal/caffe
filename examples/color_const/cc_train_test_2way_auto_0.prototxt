name: "ColorConstancy"
layer {
  name: "data_label"
  type: "IllumImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  illum_image_data_param {
    source: "/home/sw015/data/gs568/results/rb_og_rbg/fold_0.txt"
    source: "/home/sw015/data/gs568/results/rb_og_rbg/fold_1.txt"
	root_folder: "/home/sw015/data/gs568/results/rb_og_rbg/"
	scale: 1
	batch_size: 128
	crop_size: 44
	label_dim: 2
	mirror: true
	shuffle: true
	patch_per_image: 8
	cache: true
  }
}
layer {
  name: "data_label"
  type: "IllumImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  illum_image_data_param {
    source: "/home/sw015/data/gs568/results/rb_og_rbg/fold_2.txt"
	root_folder: "/home/sw015/data/gs568/results/rb_og_rbg/"
	scale: 1
	batch_size: 128
	crop_size: 44
	label_dim: 2
	mirror: false
	shuffle: true
	patch_per_image: 16
	cache: true
  }
}
layer {
  name: "log_data"
  type: "Log"
  bottom: "data"
  top: "log_data_0"
  log_param {
    shift: 1e-9
  }
}
layer {
  name: "copy_log_data"
  type: "Split"
  bottom: "log_data_0"
  top: "log_data"
  top: "log_data_brc"
}
layer {
  name: "log_label"
  type: "Log"
  bottom: "label"
  top: "log_label"
}
layer {
  name: "sub_mean"
  type: "MVNO"
  bottom: "log_data"
  top: "sm_log_data"
  top: "mean"
  mvno_param {
    normalize_variance:  false
    sub_mean: true
    output_mean: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "sm_log_data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
	kernel_size: 8
	stride: 4
	weight_filler {
	  type: "msra"
	  variance_norm: FAN_IN
	}
  }
}
layer {
  name: "reluc1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
	kernel_size: 4
	stride: 2
	weight_filler {
	  type: "msra"
	  variance_norm: FAN_IN
	}
  }
}
layer {
  name: "reluc2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
################################### copy features
layer {
  name: "copy_feat"
  type: "Split"
  bottom: "conv2"
  top: "conv2_0"
  top: "conv2_1"
}
################################### branch 0
layer {
  name: "ip1_0"
  type: "InnerProduct"
  bottom: "conv2_0"
  top: "ip1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
	weight_filler {
	  type: "msra"
	  variance_norm: FAN_IN
	}
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "ip1_0"
  top: "ip1_0"
}
layer {
  name: "ip2_0"
  type: "InnerProduct"
  bottom: "ip1_0"
  top: "ip2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
	weight_filler {
	  type: "msra"
	  variance_norm: FAN_IN
	}
  }
}
#################################### branch 1
layer {
  name: "ip1_1"
  type: "InnerProduct"
  bottom: "conv2_1"
  top: "ip1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "ip1_1"
  top: "ip1_1"
}
layer {
  name: "ip2_1"
  type: "InnerProduct"
  bottom: "ip1_1"
  top: "ip2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
################################### copy mean and label
layer {
  name: "copy_mean"
  type: "Split"
  bottom: "mean"
  top: "mean_0"
  top: "mean_1"
}
layer {
  name: "copy_label"
  type: "Split"
  bottom: "log_label"
  top: "log_label_0"
  top: "log_label_1"
}
################################### branch 0
layer {
  name: "add_mean_0"
  type: "Eltwise"
  bottom: "ip2_0"
  bottom: "mean_0"
  top: "ip2_add_mean_0"
}
layer {
  name: "euclid_dist_0"
  type: "EuclideanDist"
  bottom: "ip2_add_mean_0"
  bottom: "log_label_0"
  top: "l2_dist_0"
}
################################## branch 1
layer {
  name: "add_mean_1"
  type: "Eltwise"
  bottom: "ip2_1"
  bottom: "mean_1"
  top: "ip2_add_mean_1"
}  
layer {
  name: "euclid_dist_1"
  type: "EuclideanDist"
  bottom: "ip2_add_mean_1"
  bottom: "log_label_1"
  top: "l2_dist_1"
}
################################## join in
layer {
  name: "concat_branches"
  type: "Concat"
  bottom: "l2_dist_0"
  bottom: "l2_dist_1"
  top: "l2_dist_all"
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "l2_dist_all"
  top: "l2_dist_flatten"
}
################################## compute weights
layer {
  name: "brc_conv1"
  type: "Convolution"
  bottom: "log_data_brc"
  top: "conv1_brc"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
        kernel_size: 8
        stride: 4
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
layer {
  name: "brc_reluc1"
  type: "ReLU"
  bottom: "conv1_brc"
  top: "conv1_brc"
}
layer {
  name: "brc_conv2"
  type: "Convolution"
  bottom: "conv1_brc"
  top: "conv2_brc"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
        kernel_size: 4
        stride: 2
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
layer {
  name: "brc_reluc2"
  type: "ReLU"
  bottom: "conv2_brc"
  top: "conv2_brc"
}
layer {
  name: "brc_ip1"
  type: "InnerProduct"
  bottom: "conv2_brc"
  top: "ip1_brc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
layer {
  name: "brc_relu1"
  type: "ReLU"
  bottom: "ip1_brc"
  top: "ip1_brc"
}
layer {
  name: "brc_ip2"
  type: "InnerProduct"
  bottom: "ip1_brc"
  top: "ip2_brc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
        weight_filler {
          type: "msra"
          variance_norm: FAN_IN
        }
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "ip2_brc"
  top: "branch_weight"
}
################################## 
layer {
  name: "weighted_branches"
  type: "Eltwise"
  bottom: "l2_dist_flatten"
  bottom: "branch_weight"
  top: "l2_dist_weighted"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "sum_loss"
  type: "SumLoss"
  bottom: "l2_dist_weighted"
  top: "l2_loss"
  loss_weight: 1
}
